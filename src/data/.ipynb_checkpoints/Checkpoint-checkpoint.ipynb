{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks, Checkpoint #1\n",
    "\n",
    "Faculty: FIIT <br>\n",
    "Academic year: 2019/2020 <br>\n",
    "Authors: Andrej Gáfrik, Martin Grega <br>\n",
    "\n",
    "\n",
    "We had to change out source data to https://figshare.com/articles/Wikipedia_Detox_Data/4054689, because of bad formatting in data, which we couldn't solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 1.8MB/s eta 0:00:01    |██████████▉                     | 3.5MB 1.7MB/s eta 0:00:05\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.0)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 1.9MB/s eta 0:00:01     |█████████████▌                  | 215kB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.6.1->pandas) (1.11.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-0.25.3 pytz-2019.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 625kB/s eta 0:00:01     |█████████▌                      | 430kB 625kB/s eta 0:00:02     |██████████████████████████▏     | 1.2MB 625kB/s eta 0:00:01     |█████████████████████████████▍  | 1.3MB 625kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from nltk) (1.11.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1450717 sha256=61db64710bb983ae5f0ed6e41dcf1a7a6e2749759f1c275bdc6a2cdf41b78866\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tokenizer\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/ef/2e9a3f764907a46e965d0c311eab8312290dfe723ae10ed2d776583174e0/tokenizer-1.4.1-py2.py3-none-any.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 864kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tokenizer\n",
      "Successfully installed tokenizer-1.4.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "# !pip install tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('../../data/attack_annotated_comments.tsv', sep='\\t')\n",
    "labels = pd.read_csv('../../data/attack_annotations.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments.drop(columns=['year','logged_in','ns','sample','split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>699848324</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>699851288</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115861</th>\n",
       "      <td>699857133</td>\n",
       "      <td>NEWLINE_TOKEN:The way you're trying to describ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115862</th>\n",
       "      <td>699891012</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115863</th>\n",
       "      <td>699897151</td>\n",
       "      <td>Alternate option===NEWLINE_TOKENIs there perha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rev_id                                            comment\n",
       "0           37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...\n",
       "1           44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...\n",
       "2           49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...\n",
       "3           89320   Next, maybe you could work on being less cond...\n",
       "4           93890               This page will need disambiguation. \n",
       "...           ...                                                ...\n",
       "115859  699848324  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...\n",
       "115860  699851288  NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...\n",
       "115861  699857133  NEWLINE_TOKEN:The way you're trying to describ...\n",
       "115862  699891012  NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...\n",
       "115863  699897151  Alternate option===NEWLINE_TOKENIs there perha...\n",
       "\n",
       "[115864 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems in data:\n",
    " - tabular, new line and qoutes were replaced with tab_token, new_line token and `\n",
    " - punctuation\n",
    " - more spaces between words\n",
    " - empty strings\n",
    " - abbreviations like i will = i'll , didn't = did not, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.drop(columns=['worker_id','quoting_attack','recipient_attack','third_party_attack','other_attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365212</th>\n",
       "      <td>699897151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365213</th>\n",
       "      <td>699897151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365214</th>\n",
       "      <td>699897151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365215</th>\n",
       "      <td>699897151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365216</th>\n",
       "      <td>699897151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1365217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id  attack\n",
       "0            37675     0.0\n",
       "1            37675     0.0\n",
       "2            37675     0.0\n",
       "3            37675     0.0\n",
       "4            37675     0.0\n",
       "...            ...     ...\n",
       "1365212  699897151     0.0\n",
       "1365213  699897151     0.0\n",
       "1365214  699897151     0.0\n",
       "1365215  699897151     0.0\n",
       "1365216  699897151     0.0\n",
       "\n",
       "[1365217 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = labels.groupby('rev_id')['attack'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>699848324</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>699851288</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115861</th>\n",
       "      <td>699857133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115862</th>\n",
       "      <td>699891012</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115863</th>\n",
       "      <td>699897151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rev_id    attack\n",
       "0           37675  0.000000\n",
       "1           44816  0.000000\n",
       "2           49851  0.000000\n",
       "3           89320  0.444444\n",
       "4           93890  0.000000\n",
       "...           ...       ...\n",
       "115859  699848324  0.111111\n",
       "115860  699851288  0.100000\n",
       "115861  699857133  0.000000\n",
       "115862  699891012  0.200000\n",
       "115863  699897151  0.000000\n",
       "\n",
       "[115864 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = comments.join(res.set_index('rev_id'), on='rev_id')\n",
    "data['attack'] = data['attack'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>699848324</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>699851288</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115861</th>\n",
       "      <td>699857133</td>\n",
       "      <td>NEWLINE_TOKEN:The way you're trying to describ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115862</th>\n",
       "      <td>699891012</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115863</th>\n",
       "      <td>699897151</td>\n",
       "      <td>Alternate option===NEWLINE_TOKENIs there perha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rev_id                                            comment  attack\n",
       "0           37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...     0.0\n",
       "1           44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...     0.0\n",
       "2           49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...     0.0\n",
       "3           89320   Next, maybe you could work on being less cond...     0.0\n",
       "4           93890               This page will need disambiguation.      0.0\n",
       "...           ...                                                ...     ...\n",
       "115859  699848324  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...     0.0\n",
       "115860  699851288  NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...     0.0\n",
       "115861  699857133  NEWLINE_TOKEN:The way you're trying to describ...     0.0\n",
       "115862  699891012  NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...     0.0\n",
       "115863  699897151  Alternate option===NEWLINE_TOKENIs there perha...     0.0\n",
       "\n",
       "[115864 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115864 entries, 0 to 115863\n",
      "Data columns (total 3 columns):\n",
      "rev_id     115864 non-null int64\n",
      "comment    115864 non-null object\n",
      "attack     115864 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 2.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In out data are newlines, tabulators and quotions marks replaced, so we need to delete this replacement\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\",\"\"))\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\",\"\"))\n",
    "data['comment'] = data['comment'].apply(lambda x: x.replace(\"``\",'\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/prashantkikani/pooled-gru-with-preprocessing\n",
    "repl = {\n",
    "    \"&lt;3\": \" good \",\n",
    "    \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"`d\": \" would\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"e.g\" : \"eg\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting comments by spaces\n",
    "comments = data['comment'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "abbr = [i for i in repl.keys()]\n",
    "result = []\n",
    "for index in range(len(comments)):\n",
    "    new_comment = \"\"\n",
    "    for word in comments[index]:\n",
    "        word = word.lower()\n",
    "        word = re.sub(r\"n't\", \" not\", word)\n",
    "        word = re.sub(r\"\\ 's\", \" not\", word)\n",
    "        word = re.sub(r\"\\ 've\", \" not\", word)\n",
    "        word = re.sub(r\"\\ 'd\", \" not\", word)\n",
    "        word = re.sub(r\"\\ ll\", \" not\", word)\n",
    "        if re.search(\"^http.+|^www.+\",word): # deleting links\n",
    "            continue\n",
    "        elif word in abbr:\n",
    "            new_comment += repl[word]\n",
    "            new_comment += \" \"\n",
    "            word = repl[word]\n",
    "        elif re.search(\"[^a-zA-Z ]+\",word): # only alphabet\n",
    "            new_comment += re.sub(\"[^a-zA-Z ]+\",\" \",word)\n",
    "            new_comment += \" \"\n",
    "        else:\n",
    "            new_comment += word  \n",
    "            new_comment += \" \"\n",
    "            \n",
    "    new_comment = \" \".join(new_comment.split())        \n",
    "   # print(\"Old = \", comments[index])\n",
    "   # print(\"New = \", new_comment)\n",
    "    result.append(new_comment)\n",
    "data[\"comment\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>this is not creative those are the dictionary ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less npov th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>true or false the situation as of march was su...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>next maybe you could work on being less condes...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>this page will need disambiguation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>699848324</td>\n",
       "      <td>these sources do not exactly exude a sense of ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>699851288</td>\n",
       "      <td>the institute for historical review is a peer ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115861</th>\n",
       "      <td>699857133</td>\n",
       "      <td>the way you re trying to describe it in this a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115862</th>\n",
       "      <td>699891012</td>\n",
       "      <td>warning there is clearly a protectionist regim...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115863</th>\n",
       "      <td>699897151</td>\n",
       "      <td>alternate option is there perhaps enough newsw...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rev_id                                            comment  attack\n",
       "0           37675  this is not creative those are the dictionary ...     0.0\n",
       "1           44816  the term standard model is itself less npov th...     0.0\n",
       "2           49851  true or false the situation as of march was su...     0.0\n",
       "3           89320  next maybe you could work on being less condes...     0.0\n",
       "4           93890                 this page will need disambiguation     0.0\n",
       "...           ...                                                ...     ...\n",
       "115859  699848324  these sources do not exactly exude a sense of ...     0.0\n",
       "115860  699851288  the institute for historical review is a peer ...     0.0\n",
       "115861  699857133  the way you re trying to describe it in this a...     0.0\n",
       "115862  699891012  warning there is clearly a protectionist regim...     0.0\n",
       "115863  699897151  alternate option is there perhaps enough newsw...     0.0\n",
       "\n",
       "[115864 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing empty strings with nan\n",
    "data['comment'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115864 entries, 0 to 115863\n",
      "Data columns (total 3 columns):\n",
      "rev_id     115864 non-null int64\n",
      "comment    115825 non-null object\n",
      "attack     115864 non-null float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 2.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking nan values on data\n",
    "data.info()\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nan rows\n",
    "data.dropna(subset=['comment'], inplace=True)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def stemmer(comment):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = comment.split()\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    stemmed\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "t = data['comment'].map(lambda x: stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stemmed_comments'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving cleaned data\n",
    "data.to_csv('../../data/preprocessed_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('../../data/preprocessed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Training of our tokenizer\n",
    "tokenizer.fit_on_texts(data['stemmed_comments'])\n",
    "#tokenizer.fit_on_texts(data['comment'])\n",
    "\n",
    "# Number of unique words in our data\n",
    "vocab_len = len(tokenizer.word_index) + 1\n",
    "\n",
    "#converting comment into numeric form, each unique word has a number, so comment will be rewrite into numbers\n",
    "embedded = tokenizer.texts_to_sequences(data['stemmed_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_sentence_len = len(max(embedded, key= len))\n",
    "\n",
    "#Adding zeroes to end of eat embeded sentece to len of the longest sentence\n",
    "padded_comments = pad_sequences(embedded, longest_sentence_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = open('../../data/glove.6B.50d.txt', encoding=\"utf8\")\n",
    "from numpy import array\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test data\n",
    "size_train = round(len(padded_comments)* 0.8)\n",
    "\n",
    "train_padded = padded_comments[:size_train]\n",
    "train_attack =asarray(data['attack'][:size_train], dtype='int32')\n",
    "\n",
    "test_padded = padded_comments[size_train + 1:]\n",
    "test_attack = asarray(data['attack'][size_train + 1:], dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing glove dictonary\n",
    "glove_dict = dict()\n",
    "\n",
    "#according to glove file, first is word and next are vectors\n",
    "for line in glove:\n",
    "    splitted = line.split()\n",
    "    word = splitted[0]\n",
    "    vectors = asarray(splitted[1:], dtype='float32')\n",
    "    glove_dict [word] = vectors \n",
    "\n",
    "\n",
    "glove.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "zle = 0\n",
    "# create dict with only words in out data\n",
    "word_matrix = zeros((vocab_len, 50))\n",
    "# iterate throuh all words in our data and find vector for them\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    vectors = glove_dict.get(word)\n",
    "    if vectors is not None:\n",
    "        word_matrix[index] = vectors # pretrained word embedings with words from our comments\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU,Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "def GRU_model():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_len,50,embeddings_initializer = Constant(word_matrix),input_length=longest_sentence_len,trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(GRU(units = 1, dropout=0.2, recurrent_dropout = 0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2831, 50)          5603050   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 1)                 159       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 5,603,211\n",
      "Trainable params: 161\n",
      "Non-trainable params: 5,603,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = GRU_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not working in notebook and docker, trained in google colab, screen of results in model\n",
    "model.fit(train_padded,train_attack,batch_size=128, epochs=3, validation_data=(test_padded,test_attack),verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of training (because used wrong verbose parameter :( )\n",
    "- Epoch 1: 1110S - loss: 0.4846 - acc: 0.8798 - val_loss: 0.3513 - val_acc: 0.8951\n",
    "- Epoch 2: 1284S - loss: 0.3699 - acc: 0.8798 - val_loss: 0.3373 - val_acc: 0.8951\n",
    "- Epoch 3: 1290S - loss: 0.3681 - acc: 0.8798 - val_loss: 0.3571 - val_acc: 0.8951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GRU_model_1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,SimpleRNN\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "def Simple_RNN():\n",
    "    model = Sequential()\n",
    "    embedding_layer = Embedding(vocab_len,50,embeddings_initializer = Constant(word_matrix),input_length=longest_sentence_len,trainable=False)\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(128, activation = 'tanh', dropout = 0.1))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2831, 50)          5603050   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               22912     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 5,626,091\n",
      "Trainable params: 23,041\n",
      "Non-trainable params: 5,603,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Simple_RNN()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92660 samples, validate on 23164 samples\n",
      "Epoch 1/3\n",
      "92660/92660 [==============================] - 2336s 25ms/sample - loss: 0.1095 - accuracy: 0.8725 - val_loss: 0.0966 - val_accuracy: 0.8917\n",
      "Epoch 2/3\n",
      "92660/92660 [==============================] - 2388s 26ms/sample - loss: 0.1054 - accuracy: 0.8804 - val_loss: 0.0968 - val_accuracy: 0.8917\n",
      "Epoch 3/3\n",
      "92660/92660 [==============================] - 2506s 27ms/sample - loss: 0.1054 - accuracy: 0.8804 - val_loss: 0.0968 - val_accuracy: 0.8917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2d4097e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_padded,train_attack,batch_size=128, epochs=3, validation_data=(test_padded,test_attack),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('Simple_RNN_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
